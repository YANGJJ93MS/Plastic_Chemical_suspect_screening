{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final update 2024-12-11\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import random as rd\n",
    "import matplotlib\n",
    "import warnings\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yangj\\AppData\\Local\\Temp\\ipykernel_45332\\2005536182.py:3: DtypeWarning: Columns (19,20,59) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  PLASTICMAP = pd.read_csv(\"D:/UCSF_postdoc_topic/REVEAL_topics/REVEAL_200samples_analysis/plastic_map_chemlist/PLASTICMAP_comTox dashboard.csv\")\n"
     ]
    }
   ],
   "source": [
    "targetmz_path = [\"D:/UCSF_postdoc_topic/REVEAL_topics/REVEAL_200samples_analysis/plastic_map_chemlist/Plastic_Chemical_withRT_CFMID_spectrumdatabase_chemical_annotation_20250404.csv\"] #plastic chemical list with predicted/library RT, CRMID, and spectrum ID match record,\n",
    "plastics_chem = pd.read_csv(targetmz_path[0])\n",
    "PLASTICMAP = pd.read_csv(\"D:/UCSF_postdoc_topic/REVEAL_topics/REVEAL_200samples_analysis/plastic_map_chemlist/PLASTICMAP_comTox dashboard.csv\")\n",
    "#check if DATA_SOURCES column exists in PLASTICMAP\n",
    "plastics_chem = pd.merge(plastics_chem, PLASTICMAP[['DTXSID', 'DATA_SOURCES']], how='left', left_on='DTXSID', right_on='DTXSID')\n",
    "plastics_chem.to_csv(\"D:/UCSF_postdoc_topic/REVEAL_topics/REVEAL_200samples_analysis/plastic_map_chemlist/Plastic_Chemical_withRT_CFMID_spectrumdatabase_chemical_annotation_20250404.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_peak_area_file(input_path: str,\n",
    "                           output_path: str,\n",
    "                           adduct_filter: str = \"[M+H]+\",\n",
    "                           drop_prefix: str = \"BH\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read a raw alignment TSV, extract peak‐area data, filter by adduct,\n",
    "    drop unwanted columns, and write to CSV.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_path : str\n",
    "        Path to the raw TSV (no header, all cols as text).\n",
    "    output_path : str\n",
    "        Path where the filtered CSV will be written.\n",
    "    adduct_filter : str, default \"[M+H]+\"\n",
    "        Which adduct string to keep (e.g. \"[M+H]+\", \"[M-H]-\").\n",
    "    drop_prefix : str, default \"BH\"\n",
    "        Prefix of any columns to drop (e.g. batch‐correction flags).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The filtered peak‐area DataFrame.\n",
    "    \"\"\"\n",
    "    # --- 1) Read raw data block ---\n",
    "    raw = pd.read_csv(\n",
    "        input_path,\n",
    "        sep='\\t',\n",
    "        header=None,\n",
    "        dtype=str,\n",
    "        keep_default_na=False\n",
    "    )\n",
    "    # drop the first 4 rows to get to the peak-area table\n",
    "    peak_block = raw.iloc[4:].reset_index(drop=True)\n",
    "    \n",
    "    # --- 2) Set column names from the first row, then drop it ---\n",
    "    peak_block.columns = peak_block.iloc[0]\n",
    "    peak_block = peak_block.iloc[1:].reset_index(drop=True)\n",
    "    \n",
    "    # --- 3) Extract and save the adduct list before numeric conversion ---\n",
    "    adduct_list = peak_block['Adduct type'].astype(str).tolist()\n",
    "    \n",
    "    # --- 4) Select desired columns ---\n",
    "    cols = list(peak_block.columns)\n",
    "    msms_idx = cols.index('MS/MS spectrum')\n",
    "    keep_cols = ['Average Rt(min)', 'Average Mz'] + cols[msms_idx+1:-2]\n",
    "    \n",
    "    df = (\n",
    "        peak_block\n",
    "        .loc[:, keep_cols]\n",
    "        .apply(pd.to_numeric, errors='coerce')\n",
    "    )\n",
    "    \n",
    "    # --- 5) Add adduct column, filter, and drop it again ---\n",
    "    df['Adduct'] = adduct_list\n",
    "    df = df.loc[df['Adduct'] == adduct_filter].drop(columns=['Adduct'])\n",
    "    \n",
    "    # --- 6) Drop any columns whose names start with drop_prefix ---\n",
    "    df = df.loc[:, ~df.columns.str.startswith(drop_prefix)]\n",
    "    \n",
    "    # --- 7) Write out to CSV and return ---\n",
    "    df.to_csv(output_path, index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "# For [M+H]+\n",
    "df_pos = process_peak_area_file(\n",
    "    input_path=r\"D:/UCSF_postdoc_topic/REVEAL_topics/REVEAL_200samples_analysis/Pos_AlignmentResults/Area_1_2024_11_04_23_46_26.txt\",\n",
    "    output_path=r\"D:/UCSF_postdoc_topic/REVEAL_topics/REVEAL_200samples_analysis/Pos_AlignmentResults/raw_peak_area_before_bc_20250429.csv\",\n",
    "    adduct_filter=\"[M+H]+\"\n",
    ")\n",
    "\n",
    "# For [M-H]−\n",
    "df_neg = process_peak_area_file(\n",
    "    input_path=r\"D:/UCSF_postdoc_topic/REVEAL_topics/REVEAL_200samples_analysis/Neg_AlignmentResults/Area_1_2024_11_04_16_24_07.txt\",\n",
    "    output_path=r\"D:/UCSF_postdoc_topic/REVEAL_topics/REVEAL_200samples_analysis/Neg_AlignmentResults/raw_peak_area_before_bc_20250429.csv\",\n",
    "    adduct_filter=\"[M-H]-\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension of the peak area data: (40004, 463)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching compounds: 100%|██████████| 5267/5267 [01:23<00:00, 62.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique matched feature from peak area table: 6248\n",
      "Number of unique chemical matched: 2190\n",
      "dimension of feature table filtered by intensity: (12058, 225)\n",
      "Number of columns retained after intensity filtering: 211\n",
      "dimension of the filtered data: (12058, 211)\n"
     ]
    }
   ],
   "source": [
    "# Load peak area data for positive ion mode after batch correction\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "peakarea_path = [\"D:/UCSF_postdoc_topic/REVEAL_topics/REVEAL_200samples_analysis/Pos_AlignmentResults/raw_peak_area_before_bc.csv\"] #raw peak area before batch correction (40004, 403)\n",
    "targetmz_path = [\"D:/UCSF_postdoc_topic/REVEAL_topics/REVEAL_200samples_analysis/plastic_map_chemlist/Plastic_Chemical_withRT_CFMID_spectrumdatabase_chemical_annotation_20250404.csv\"] #plastic chemical list with predicted/library RT, CRMID, and spectrum ID match record,\n",
    "\n",
    "#load peak area data\n",
    "pos_peak_area = pd.read_csv(peakarea_path[0])\n",
    "print(f'dimension of the peak area data: {pos_peak_area.shape}')\n",
    "# Load target mz data\n",
    "targetmzdat_pos = pd.read_csv(targetmz_path[0])\n",
    "targetmzdat_pos['mz'] = targetmzdat_pos['Monoisotopic_Mass_ready'] + 1.007825 #looking at M+H adducts\n",
    "\n",
    "# Select relevant columns for inquiry\n",
    "peak_area_inquiry = pos_peak_area[['Average Rt(min)', 'Average Mz'] + [col for col in pos_peak_area.columns if col.startswith('BH')]]\n",
    "\n",
    "# Function to calculate ppm difference\n",
    "def ppm_difference(value1, value2):\n",
    "    return abs(value1 - value2) / value1 * 1e6\n",
    "\n",
    "ppm_threshold = 10 #ppm threshold for matching\n",
    "matched_rows_pos = []\n",
    "matched_summary = []\n",
    "\n",
    "# MS1 search and matching\n",
    "for _, chem_row in tqdm(targetmzdat_pos.iterrows(), total=targetmzdat_pos.shape[0], desc=\"Matching compounds\"):\n",
    "    mw = chem_row['mz']\n",
    "    matches = peak_area_inquiry[peak_area_inquiry['Average Mz'].apply(lambda mz: ppm_difference(mz, mw) <= ppm_threshold)]\n",
    "    if not matches.empty:\n",
    "        # Append the matches along with the corresponding compound information\n",
    "        for _, match_row in matches.iterrows():\n",
    "            matched_rows_pos.append({\n",
    "                **match_row,\n",
    "                'Matched Compound': chem_row['SMILES'],\n",
    "                'PREFERRED_NAME': chem_row.get('PREFERRED_NAME', None),\n",
    "                'DTXSID_Hits': chem_row.get('DTXSID', None),\n",
    "                'DTXSID': chem_row.get('DTXSID', None),\n",
    "                'InChiKey_origin': chem_row.get('INCHIKEY', None),\n",
    "                'MOLECULAR_FORMULA_original': chem_row.get('MOLECULAR_FORMULA', None),\n",
    "                'Compound_comment': chem_row.get('QC_NOTES', None),\n",
    "                'SMILES_STD': chem_row.get('SMILES_ready', None),\n",
    "                \"Monoisotopic_mass_ready\": chem_row.get('Monoisotopic_Mass_ready', None),\n",
    "                \"PredictedRT\": chem_row.get('PredRT_Retip', None),\n",
    "                \"PredictedRT_lower\": chem_row.get('predRT_lower', None),\n",
    "                \"PredictedRT_upper\": chem_row.get('predRT_higher', None),\n",
    "                'RT_library' : chem_row.get('RT_lib', None),\n",
    "                'RT_polarity' : chem_row.get('Polarity', None),\n",
    "                'total_spectra_pos': chem_row.get('total_spectra_pos', None),\n",
    "                'total_pred_spectra_pos': chem_row.get('total_pred_spectra_pos', None),\n",
    "                'BloodExpo_check': chem_row.get('BloodExpo_check', None),\n",
    "                'ExposomeExplorer_check': chem_row.get('ExposomeExplorer_check', None),\n",
    "                'Function': chem_row.get('Function', None),\n",
    "                'Polymer': chem_row.get('Polymer', None),\n",
    "                'US_production': chem_row.get('US_production', None),\n",
    "                'Total_production': chem_row.get('Total_production', None),\n",
    "                'Industrial_Sector': chem_row.get('Industrial_Sector', None)\n",
    "            })\n",
    "\n",
    "# Create a DataFrame for matched MSDIAL result rows\n",
    "matched_peak_area_df_pos = pd.DataFrame(matched_rows_pos)\n",
    "\n",
    "# drop rows with duplicated column values at Average Rt(min) and Average Mz, retaining the first occurrence\n",
    "matched_peak_area_df_pos_uniquemzrt = matched_peak_area_df_pos.drop_duplicates(subset=['Average Rt(min)', 'Average Mz'], keep='first')\n",
    "\n",
    "#\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "folder_name = \"D:/UCSF_postdoc_topic/REVEAL_topics/REVEAL_200samples_analysis/Pos_AlignmentResults/\"\n",
    "filename = \"unique_features_accuratemassmathced_database_forallsamples_pos\"\n",
    "filetime = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "matched_peak_area_df_pos_uniquemzrt.to_csv(os.path.join(folder_name, f\"{filename}_{filetime}.csv\"),index=False)\n",
    "\n",
    "print(f\"Number of unique matched feature from peak area table: {matched_peak_area_df_pos_uniquemzrt.shape[0]}\")\n",
    "matched_peak_area_df_pos_uniquechemical = matched_peak_area_df_pos.drop_duplicates(subset=['InChiKey_origin'], keep='first')\n",
    "print(f'Number of unique chemical matched: {matched_peak_area_df_pos_uniquechemical.shape[0]}')\n",
    "\n",
    "# Step 3: Handling technical duplicates and calculating mean values\n",
    "bh_columns = [col for col in matched_peak_area_df_pos.columns if col.startswith('BH')]\n",
    "mean_columns = {}\n",
    "for col in bh_columns:\n",
    "    base_col = col.split('_')[0]\n",
    "    if base_col not in mean_columns:\n",
    "        duplicate_cols = [c for c in bh_columns if c.startswith(base_col)]\n",
    "        mean_columns[base_col] = matched_peak_area_df_pos[duplicate_cols].mean(axis=1)\n",
    "\n",
    "# Retain only the columns with calculated mean values\n",
    "matched_peak_area_df_pos = pd.concat([matched_peak_area_df_pos.drop(columns=bh_columns), pd.DataFrame(mean_columns)], axis=1)\n",
    "\n",
    "#output the matched peak area data\n",
    "#rank the feature by rt AND mz\n",
    "matched_peak_pos = matched_peak_area_df_pos.sort_values(by=['Average Rt(min)', 'Average Mz'])\n",
    "\n",
    "#filerted features with intensity lower than 5000 \n",
    "peak_areapos  = matched_peak_pos[[col for col in matched_peak_pos.columns if col.startswith('BH')]]\n",
    "row_medianspos  = peak_areapos.median(axis=1)\n",
    "peak_indexpos  = row_medianspos[row_medianspos >= 0].index\n",
    "filter_resultspos  = matched_peak_pos.loc[peak_indexpos]\n",
    "print(f'dimension of feature table filtered by intensity: {filter_resultspos.shape}')\n",
    "\n",
    "# Step 4: Retain columns with median values > 5000, filter non-numeric values, and perform DataFrame transpose\n",
    "filtered_df = matched_peak_area_df_pos.apply(pd.to_numeric, errors='coerce')  # Convert non-numeric values to NaN\n",
    "filtered_df = filtered_df.loc[:, (filtered_df.median(axis=0) >= 0)].dropna(how='all', axis=1)  # Retain columns with median value > 5000\n",
    "\n",
    "# Count the number of retained columns after intensity filtering\n",
    "num_retained_columns = filtered_df.shape[1] \n",
    "print(f\"Number of columns retained after intensity filtering: {num_retained_columns}\")\n",
    "print(f'dimension of the filtered data: {filtered_df.shape}')\n",
    "\n",
    "# Calculate summary statistics for each sample column\n",
    "summary_stats = {\n",
    "    'Sum': filtered_df.sum(),\n",
    "    'Median': filtered_df.median(),\n",
    "    'Mean': filtered_df.mean(),\n",
    "    'Max': filtered_df.max(),\n",
    "    'Min': filtered_df.min(),\n",
    "    '95th Percentile': filtered_df.quantile(0.95),\n",
    "    '5th Percentile': filtered_df.quantile(0.05)\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the summary statistics\n",
    "summary_stats_df_pos = pd.DataFrame(summary_stats)\n",
    "# summary_stats_df_pos.to_csv(\"D:/UCSF_postdoc_topic/REVEAL_topics/REVEAL_200samples_analysis/Pos_AlignmentResults/mathced_peaks_summary_forallsamples_pos_woRT.csv\")\n",
    "\n",
    "# Transpose the summary statistics DataFrame\n",
    "# transposed_summary_df = summary_stats_df_pos.transpose()\n",
    "# Display the final DataFrame\n",
    "# print(summary_stats_df_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 226)\n",
      "(7563, 226)\n"
     ]
    }
   ],
   "source": [
    "#annotate the features according to RT_library and predictedRT\n",
    "RTmatch_threshold = 0.6#RT match threshold in minutes\n",
    "#convert RT_library to numeric values\n",
    "filter_resultspos['RT_library'] = pd.to_numeric(filter_resultspos['RT_library'], errors='coerce')\n",
    "\n",
    "for iter, row in filter_resultspos.iterrows():\n",
    "    if (pd.notnull(row['RT_library'])) and ((row['RT_polarity'] == 'both') or (row['RT_polarity'] == 'pos')):\n",
    "        if (row['Average Rt(min)'] >= row['RT_library']-0.6) and (row['Average Rt(min)'] <= row['RT_library'] + 0.6):\n",
    "            filter_resultspos.loc[iter, 'annotation_RTMS'] = '2'\n",
    "        else:\n",
    "            filter_resultspos.loc[iter, 'annotation_RTMS'] = 'NotMatched'\n",
    "    elif (row['RT_polarity'] =='na') or (row['RT_polarity'] == 'neg'):\n",
    "        filter_resultspos.loc[iter, 'annotation_RTMS'] = 'NotMatched'\n",
    "    else:\n",
    "        if (row['Average Rt(min)'] >= row['PredictedRT_lower']) & (row['Average Rt(min)'] <= row['PredictedRT_upper']):\n",
    "            filter_resultspos.loc[iter, 'annotation_RTMS'] = '3'\n",
    "        else:\n",
    "            filter_resultspos.loc[iter, 'annotation_RTMS'] = '4'\n",
    "\n",
    "print(filter_resultspos[filter_resultspos['annotation_RTMS'] == '2'].shape)\n",
    "print(filter_resultspos[filter_resultspos['annotation_RTMS'] == '3'].shape)\n",
    "\n",
    "#output the datafile for spectrum matching\n",
    "# now = datetime.datetime.now()\n",
    "# folder_name = \"D:/UCSF_postdoc_topic/REVEAL_topics/REVEAL_200samples_analysis/Pos_AlignmentResults/\"\n",
    "# filename = \"feature_annotation_RTMS_allfeatures_pos\"\n",
    "# filetime = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "# filter_resultspos.to_csv(os.path.join(folder_name, f\"{filename}_{filetime}.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching compounds: 100%|██████████| 5267/5267 [01:33<00:00, 56.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matched unique feature from peak area table: 6610\n",
      "Number of matched unique chemicals from peak area table: 2122\n",
      "#of targetedmz with hits:(2122, 15)\n",
      "(14606, 226)\n"
     ]
    }
   ],
   "source": [
    "# Importing negative alignment results\n",
    "# Negative alignment results\n",
    "peakarea_path = [\"D:/UCSF_postdoc_topic/REVEAL_topics/REVEAL_200samples_analysis/Neg_AlignmentResults/raw_peak_area_before_bc.csv\"] #raw peak area before batch correction\n",
    "targetmz_path = [\"D:/UCSF_postdoc_topic/REVEAL_topics/REVEAL_200samples_analysis/plastic_map_chemlist/Plastic_Chemical_withRT_CFMID_spectrumdatabase_chemical_annotation_20250404.csv\"] #plastic chemical list with predicted/library RT, CRMID\n",
    "\n",
    "#load peak area data\n",
    "neg_peak_area = pd.read_csv(peakarea_path[0])\n",
    "# print(f'dimention of the peak area data: {pos_peak_area_200.shape}')\n",
    "# Load target mz data\n",
    "targetmzdat_neg = pd.read_csv(targetmz_path[0])\n",
    "targetmzdat_neg['mz'] = targetmzdat_neg['MONOISOTOPIC_MASS'] - 1.007825\n",
    "\n",
    "# Select relevant columns for inquiry\n",
    "peak_area_inquiry = neg_peak_area[['Average Rt(min)', 'Average Mz'] + [col for col in neg_peak_area.columns if col.startswith('BH')]]\n",
    "\n",
    "# Function to calculate ppm difference\n",
    "def ppm_difference(value1, value2):\n",
    "    return abs(value1 - value2) / value1 * 1e6\n",
    "\n",
    "ppm_threshold = 10\n",
    "matched_rows_neg = []\n",
    "matched_summary = []\n",
    "\n",
    "# MS1 search and matching\n",
    "for _, chem_row in tqdm(targetmzdat_neg.iterrows(), total=targetmzdat_neg.shape[0], desc=\"Matching compounds\"):\n",
    "    mw = chem_row['mz']\n",
    "    matches = peak_area_inquiry[peak_area_inquiry['Average Mz'].apply(lambda mz: ppm_difference(mz, mw) <= ppm_threshold)]\n",
    "    #print(f\"Matches after ppm filtering: {matches.shape}\")  # Debugging\n",
    "    \n",
    "    if not matches.empty:\n",
    "        # Append the matches along with the corresponding compound information\n",
    "        for _, match_row in matches.iterrows():\n",
    "            matched_rows_neg.append({\n",
    "                **match_row,\n",
    "                'Matched Compound': chem_row['SMILES'],\n",
    "                'PREFERRED_NAME': chem_row.get('PREFERRED_NAME', None),\n",
    "                'DTXSID_Hits': chem_row.get('DTXSID', None),\n",
    "                'DTXSID': chem_row.get('DTXSID', None),\n",
    "                'InChiKey_origin': chem_row.get('INCHIKEY', None),\n",
    "                'MOLECULAR_FORMULA_original': chem_row.get('MOLECULAR_FORMULA', None),\n",
    "                'Compound_comment': chem_row.get('QC_NOTES', None),\n",
    "                'SMILES_STD': chem_row.get('SMILES_ready', None),\n",
    "                \"Monoisotopic_mass_ready\": chem_row.get('Monoisotopic_Mass_ready', None),\n",
    "                \"PredictedRT\": chem_row.get('PredRT_Retip', None),\n",
    "                \"PredictedRT_lower\": chem_row.get('predRT_lower', None),\n",
    "                \"PredictedRT_upper\": chem_row.get('predRT_higher', None),\n",
    "                'RT_library' : chem_row.get('RT_lib', None),\n",
    "                'RT_polarity' : chem_row.get('Polarity', None),\n",
    "                'total_spectra_neg': chem_row.get('total_spectra_neg', None),\n",
    "                'total_pred_spectra_neg': chem_row.get('total_pred_spectra_neg', None),\n",
    "                'BloodExpo_check': chem_row.get('BloodExpo_check', None),\n",
    "                'ExposomeExplorer_check': chem_row.get('ExposomeExplorer_check', None),\n",
    "                'Function': chem_row.get('Function', None),\n",
    "                'Polymer': chem_row.get('Polymer', None),\n",
    "                'US_production': chem_row.get('US_production', None),\n",
    "                'Total_production': chem_row.get('Total_production', None),\n",
    "                'Industrial_Sector': chem_row.get('Industrial_Sector', None)\n",
    "            })\n",
    "        # Record summary statistics for each targeted mz, preserving multiple hits\n",
    "        matched_summary.append({\n",
    "            'Targeted MZ': mw,\n",
    "            'Matched Count': len(matches),\n",
    "            'Average Rt(min)': matches['Average Rt(min)'].tolist(),\n",
    "            'Average Mz': matches['Average Mz'].tolist(),\n",
    "            'Mean Value': matches.iloc[:, 3:].mean(axis=1).tolist(),\n",
    "            'Max Value': matches.iloc[:, 3:].max(axis=1).tolist(),\n",
    "            'Min Value': matches.iloc[:, 3:].min(axis=1).tolist(),\n",
    "            'Std Dev': matches.iloc[:, 3:].std(axis=1).tolist(),\n",
    "            'RSD (%)': ((matches.iloc[:, 3:].std(axis=1) / matches.iloc[:, 3:].mean(axis=1)) * 100).tolist(),\n",
    "            'SMILES_STD': chem_row.get('SMILES_ready', None),\n",
    "            'DTXSID': chem_row.get('DTXSID', None),\n",
    "            'CASRN': chem_row.get('CASRN', None),\n",
    "            'Compound Name': chem_row.get('PREFERRED_NAME', None),\n",
    "            'QC_NOTES': chem_row.get('QC_NOTES', None),\n",
    "            'InChiKey_origin': chem_row.get('INCHIKEY', None)\n",
    "        })\n",
    "\n",
    "# Create a DataFrame for matched MSDIAL result rows\n",
    "matched_peak_area_df_neg = pd.DataFrame(matched_rows_neg)\n",
    "\n",
    "# drop rows with duplicated column values at Average Rt(min) and Average Mz, retaining the first occurrence\n",
    "matched_peak_area_df_neg_uniquemzrt = matched_peak_area_df_neg.drop_duplicates(subset=['Average Rt(min)', 'Average Mz'], keep='first')\n",
    "# matched_peak_area_df_neg_uniquemzrt.to_csv(\"D:/UCSF_postdoc_topic/REVEAL_topics/REVEAL_200samples_analysis/Neg_AlignmentResults/unique_features_accuratemassmathced_database_forallsamples_neg.csv\")\n",
    "matched_peak_area_df_neg_uniquechemical = matched_peak_area_df_neg.drop_duplicates(subset=['InChiKey_origin'], keep='first')\n",
    "print(f\"Number of matched unique feature from peak area table: {matched_peak_area_df_neg_uniquemzrt.shape[0]}\")\n",
    "print(f\"Number of matched unique chemicals from peak area table: {matched_peak_area_df_neg_uniquechemical.shape[0]}\")\n",
    "\n",
    "# Create a DataFrame for matched summary statistics\n",
    "matched_summary_df_neg = pd.DataFrame(matched_summary)\n",
    "print(f\"#of targetedmz with hits:{matched_summary_df_neg.shape}\")\n",
    "# matched_summary_df_neg.to_csv(\"D:/UCSF_postdoc_topic/REVEAL_topics/REVEAL_200samples_analysis/Neg_AlignmentResults/mathced_targetedmz_summary_forallsamples_Neg_woRT.csv\")\n",
    "# print(matched_summary_df_neg.shape)\n",
    "\n",
    "# Step 3: Handling technical duplicates and calculating mean values\n",
    "bh_columns = [col for col in matched_peak_area_df_neg.columns if col.startswith('BH')]\n",
    "mean_columns = {}\n",
    "for col in bh_columns:\n",
    "    base_col = col.split('_')[0]\n",
    "    if base_col not in mean_columns:\n",
    "        duplicate_cols = [c for c in bh_columns if c.startswith(base_col)]\n",
    "        mean_columns[base_col] = matched_peak_area_df_neg[duplicate_cols].mean(axis=1)\n",
    "\n",
    "# Retain only the columns with calculated mean values\n",
    "matched_peak_area_df_neg = pd.concat([matched_peak_area_df_neg.drop(columns=bh_columns), pd.DataFrame(mean_columns)], axis=1)\n",
    "\n",
    "#output the matched peak area data\n",
    "#rank the feature by rt AND mz\n",
    "matched_peak_neg = matched_peak_area_df_neg.sort_values(by=['Average Rt(min)', 'Average Mz'])\n",
    "\n",
    "#filerted features with intensity lower than 5000 \n",
    "peak_areaneg = matched_peak_neg[[col for col in matched_peak_neg.columns if col.startswith('BH')]]\n",
    "row_mediansneg = peak_areaneg.median(axis=1)\n",
    "peak_indexneg = row_mediansneg[row_mediansneg >= 0].index\n",
    "filter_resultsneg = matched_peak_neg.loc[peak_indexneg]\n",
    "print(filter_resultsneg.shape)\n",
    "# filter_resultsneg.to_csv(\"D:/UCSF_postdoc_topic/REVEAL_topics/REVEAL_200samples_analysis/Neg_AlignmentResults/matched_peak_neg_over5000_wopredRT.csv\")\n",
    "\n",
    "# Step 4: Retain columns with median values > 5000, filter non-numeric values, and perform DataFrame transpose\n",
    "# filtered_df = matched_peak_area_df_neg.apply(pd.to_numeric, errors='coerce')  # Convert non-numeric values to NaN\n",
    "# filtered_df = filtered_df.loc[:, (filtered_df.median(axis=0) >= 5000)].dropna(how='all', axis=1)  # Retain columns with median value > 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 227)\n",
      "(10216, 227)\n"
     ]
    }
   ],
   "source": [
    "# filter_resultsneg = pd.read_csv(\"D:/UCSF_postdoc_topic/REVEAL_topics/REVEAL_200samples_analysis/Neg_AlignmentResults/matched_peak_neg_over5000_wopredRT.csv\")\n",
    "\n",
    "#feature prioritization and further annotation and confirmation\n",
    "#annotate the features according to RT_library and predictedRT\n",
    "RTmatch_threshold = 0.6 #RT match threshold in minutes\n",
    "#convert RT_library to numeric values\n",
    "filter_resultsneg['RT_library'] = pd.to_numeric(filter_resultsneg['RT_library'], errors='coerce')\n",
    "\n",
    "for iter, row in filter_resultsneg.iterrows():\n",
    "    if (pd.notnull(row['RT_library'])) and ((row['RT_polarity'] == 'both') or (row['RT_polarity'] == 'neg')):\n",
    "        if (abs(row['Average Rt(min)'] - row['RT_library']) <= RTmatch_threshold):\n",
    "            filter_resultsneg.loc[iter, 'annotation_RTMS'] = '2'\n",
    "        else:\n",
    "            filter_resultsneg.loc[iter, 'annotation_RTMS'] = 'NotMatched'\n",
    "    elif (row['RT_polarity'] =='na') or (row['RT_polarity'] == 'pos'):\n",
    "        filter_resultsneg.loc[iter, 'annotation_RTMS'] = 'NotMatched'\n",
    "    else:\n",
    "        if (row['Average Rt(min)'] >= row['PredictedRT_lower']) & (row['Average Rt(min)'] <= row['PredictedRT_upper']):\n",
    "            filter_resultsneg.loc[iter, 'annotation_RTMS'] = '3'\n",
    "        else:\n",
    "            filter_resultsneg.loc[iter, 'annotation_RTMS'] = '4'\n",
    "            \n",
    "print(filter_resultsneg[filter_resultsneg['annotation_RTMS'] == '2'].shape)\n",
    "print(filter_resultsneg[filter_resultsneg['annotation_RTMS'] == '3'].shape)\n",
    "\n",
    "#output the datafile for spectrum matching\n",
    "#filter_resultsneg.to_csv(\"D:/UCSF_postdoc_topic/REVEAL_topics/REVEAL_200samples_analysis/Neg_AlignmentResults/feature_annotation_RTMS_neg_peakover5000_20241228.csv\")\n",
    "#forward to the next step for MSMS insilico or experimental matching and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(308, 230)\n",
      "(273, 229)\n"
     ]
    }
   ],
   "source": [
    "print(filter_resultsneg[filter_resultsneg['annotation_RTMS'] == 'NotMatched'].shape)\n",
    "print(filter_resultspos[filter_resultspos['annotation_RTMS'] == 'NotMatched'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 229)\n",
      "(43, 230)\n"
     ]
    }
   ],
   "source": [
    "##check hits with level 2\n",
    "level2_pos = filter_resultspos[filter_resultspos['annotation_RTMS'] == '2']\n",
    "level2_neg = filter_resultsneg[filter_resultsneg['annotation_RTMS'] == '2']\n",
    "print(level2_pos.shape)\n",
    "print(level2_neg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##retreive msms injection patch for library matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yangj\\AppData\\Local\\Temp\\ipykernel_26968\\137290428.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'NotMatched' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  filter_resultsneg.loc[iter, 'MSMS_injection2'] = 'NotMatched'\n",
      "C:\\Users\\yangj\\AppData\\Local\\Temp\\ipykernel_26968\\137290428.py:43: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'NotMatched' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  filter_resultspos.loc[iter, 'MSMS_injection2'] = 'NotMatched'\n"
     ]
    }
   ],
   "source": [
    "#acquired msms data \n",
    "neg_msmspath1 = \"D:/UCSF_postdoc_topic/REVEAL_topics/R200_MSMS/targeted_msms_check_spectrumsearch_neg.csv\"\n",
    "pos_msmspath1 = \"D:/UCSF_postdoc_topic/REVEAL_topics/R200_MSMS/targeted_msms_check_spectrumsearch_pos.csv\"\n",
    "pos_msmspath2 = \"D:/UCSF_postdoc_topic/REVEAL_topics/R200_MSMS/B1-10pool_tMSMS_04012025/feature_annotation_RTMS_pos_allfeaturesMplusH_20250401_30permin_formsinjection.csv\"\n",
    "neg_msmspath2 = \"D:/UCSF_postdoc_topic/REVEAL_topics/R200_MSMS/B1-10pool_tMSMS_04012025/feature_annotation_RTMS_neg_allfeaturesMplusH_20250401_50permin_formsinjection.csv\"\n",
    "neg_msms = pd.read_csv(neg_msmspath1)\n",
    "pos_msms = pd.read_csv(pos_msmspath1)\n",
    "neg_msms2 = pd.read_csv(neg_msmspath2)\n",
    "pos_msms2 = pd.read_csv(pos_msmspath2)\n",
    "\n",
    "#combined averageRT and averageMz to create the new column feature_id for neg_msms and pos_msms\n",
    "neg_msms['feature_id'] = neg_msms['Average Rt(min)'].astype(str) + '_' + neg_msms['Average Mz'].astype(str)\n",
    "pos_msms['feature_id'] = pos_msms['Average Rt(min)'].astype(str) + '_' + pos_msms['Average Mz'].astype(str)\n",
    "\n",
    "neg_msms2['feature_id'] = neg_msms2['Average Rt(min)'].astype(str) + '_' + neg_msms2['Average Mz'].astype(str)\n",
    "pos_msms2['feature_id'] = pos_msms2['Average Rt(min)'].astype(str) + '_' + pos_msms2['Average Mz'].astype(str)\n",
    "#output the datafile for spectrum matching\n",
    "\n",
    "#match the targeted msms list with the new feature list \n",
    "for iter, row in filter_resultsneg.iterrows():\n",
    "    matches = neg_msms[neg_msms['feature_id'] == row['feature_id']]\n",
    "    matches2 = neg_msms2[neg_msms2['feature_id'] == row['feature_id']]\n",
    "    if not matches.empty:\n",
    "        filter_resultsneg.loc[iter, 'MSMS_injection'] = matches['MSMS_injection'].values[0]\n",
    "    else:\n",
    "        filter_resultsneg.loc[iter, 'MSMS_injection'] = 'NotMatched'\n",
    "    if not matches2.empty:\n",
    "        filter_resultsneg.loc[iter, 'MSMS_injection2'] = matches2['injection'].values[0]\n",
    "    else:\n",
    "        filter_resultsneg.loc[iter, 'MSMS_injection2'] = 'NotMatched'\n",
    "\n",
    "for iter, row in filter_resultspos.iterrows():\n",
    "    matches = pos_msms[pos_msms['feature_id'] == row['feature_id']]\n",
    "    matches2 = pos_msms2[pos_msms2['feature_id'] == row['feature_id']]\n",
    "    if not matches.empty:\n",
    "        filter_resultspos.loc[iter, 'MSMS_injection'] = matches['MSMS_injection'].values[0]\n",
    "    else:\n",
    "        filter_resultspos.loc[iter, 'MSMS_injection'] = 'NotMatched'\n",
    "    if not matches2.empty:\n",
    "        filter_resultspos.loc[iter, 'MSMS_injection2'] = matches2['injection'].values[0]\n",
    "\n",
    "    else:\n",
    "        filter_resultspos.loc[iter, 'MSMS_injection2'] = 'NotMatched'\n",
    "\n",
    "#output the datafile for spectrum matching\n",
    "# filter_resultspos.to_csv(\"D:/UCSF_postdoc_topic/REVEAL_topics/REVEAL_200samples_analysis/Pos_AlignmentResults/feature_annotation_RTMS_pos_MSMSinjection.csv\")\n",
    "# filter_resultsneg.to_csv(\"D:/UCSF_postdoc_topic/REVEAL_topics/REVEAL_200samples_analysis/Neg_AlignmentResults/feature_annotation_RTMS_neg_MSMSinjection.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_resultspos.to_csv(\"D:/UCSF_postdoc_topic/REVEAL_topics/REVEAL_200samples_analysis/Pos_AlignmentResults/feature_annotation_RTMS_pos_MSMSinjection.csv\") #(12058,229)\n",
    "filter_resultsneg.to_csv(\"D:/UCSF_postdoc_topic/REVEAL_topics/REVEAL_200samples_analysis/Neg_AlignmentResults/feature_annotation_RTMS_neg_MSMSinjection.csv\") #(14606,230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetmz_path = [\"D:/UCSF_postdoc_topic/REVEAL_topics/REVEAL_200samples_analysis/plastic_map_chemlist/Plastic_Chemical_withRT_CFMID_spectrumdatabase_chemical_annotation_20250404.csv\"] #plastic chemical list with predicted/library RT, CRMID, and spectrum ID match record,\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "echoenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
